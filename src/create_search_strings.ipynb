{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2c60fd3a-61cb-4250-9eca-8f3f07bc16a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run lit_utility_functions_2025.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1c96c664-2429-433b-8efa-e3e713eba316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matching_words(pattern, bound_pattern=True):\n",
    "  \"\"\"\n",
    "  Finds all English words that match a given regular expression pattern.\n",
    "\n",
    "  Args:\n",
    "    pattern: The regular expression pattern (string).\n",
    "\n",
    "  Returns:\n",
    "    A list of English words that match the pattern.  Returns an empty list if no words match\n",
    "    or if there's an invalid regex pattern.  Prints a warning if the NLTK words corpus is not found.\n",
    "  \"\"\"\n",
    "  if bound_pattern:\n",
    "      pattern = f'^{pattern}$'\n",
    "    \n",
    "  try:\n",
    "    regex = re.compile(pattern)\n",
    "  except re.error as e:\n",
    "    print(f\"Invalid regular expression pattern: {e}\")\n",
    "    return []\n",
    "\n",
    "  try:\n",
    "    english_words = words.words()\n",
    "  except LookupError:\n",
    "    print(\"Warning: NLTK words corpus not found. Downloading...\")\n",
    "    try:\n",
    "      nltk.download('words')\n",
    "      english_words = words.words()\n",
    "    except Exception as e:\n",
    "      print(f\"Error downloading NLTK words corpus: {e}\")\n",
    "      return []\n",
    "        \n",
    "  matching_words = [word for word in english_words if regex.search(word)]\n",
    "  \n",
    "  return matching_words\n",
    "\n",
    "def combinate_concats(prefixes, suffixes, separators=[\" \", \"-\", \"\"]):\n",
    "    \"\"\"\n",
    "    Generates all combinations using itertools.product (most efficient).\n",
    "    \"\"\"\n",
    "    combinations = [\n",
    "        \"\".join(combination)\n",
    "        for combination in itertools.product(prefixes, separators, suffixes)\n",
    "    ]\n",
    "    return combinations\n",
    "\n",
    "def plural_form_exists(word):\n",
    "    \"\"\"\n",
    "    Checks if a plausible plural form of a word exists, with improved logic\n",
    "    and handling of irregular plurals.  Uses WordNet and a rule-based fallback.\n",
    "\n",
    "    Args:\n",
    "      word: The word (string) to check.\n",
    "\n",
    "    Returns:\n",
    "      True if a plausible plural form is found, False otherwise.\n",
    "    \"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # 1. Check if the word is already plural (common case):\n",
    "    if wordnet.synsets(word) and any(lemma.name().endswith('s') for\n",
    "                                     synset in wordnet.synsets(word) for lemma in synset.lemmas()):\n",
    "       return True\n",
    "\n",
    "    # 2. Lemmatize the word (get the singular form):\n",
    "    lemma = lemmatizer.lemmatize(word, wordnet.NOUN)\n",
    "\n",
    "\n",
    "    #3. Check if word is the lemma (if so, it is most likely singular)\n",
    "    if lemma != word:\n",
    "        return True #Word is not the lemma (it's likely already a plural form)\n",
    "    \n",
    "    # 4. If lemma and word are the same, then add an s and try again with wordnet\n",
    "    if wordnet.synsets(word + 's'):\n",
    "        return True\n",
    "    \n",
    "    # 5. Try common plural endings\n",
    "    if word.endswith((\"s\", \"x\", \"z\", \"ch\", \"sh\")):\n",
    "        plural = word + \"es\"\n",
    "    elif word.endswith(\"y\") and len(word) > 1 and word[-2] not in \"aeiou\":\n",
    "        plural = word[:-1] + \"ies\"\n",
    "    else:\n",
    "        plural = word + \"s\"\n",
    "    \n",
    "    if wordnet.synsets(plural):\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "    \n",
    "def textblob_pluralize(word):\n",
    "    w = Word(word)\n",
    "    return w.pluralize()\n",
    "\n",
    "def get_spelling_variants(word):\n",
    "    \"\"\"Gets American and British spelling variants of a word using bream.\"\"\"\n",
    "    variants = set()\n",
    "    variants.add(word)  # Add the original word\n",
    "\n",
    "    try:\n",
    "      #The following lines will generate errors if the words are not int he dictionary. We capture these.\n",
    "        american = bream.to_american(word)\n",
    "        variants.add(american)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        british = bream.to_british(word)\n",
    "        variants.add(british)\n",
    "    except:\n",
    "      pass\n",
    "    return list(variants)\n",
    "\n",
    "def create_generic_search_string():\n",
    "    combo1_1 = [\"ecologic\\\\S*\", [\"eco\", \"hydrologic\\\\S*\"], [\"hydro\", \"ecologic\\\\S*\"],\n",
    "                'environmental', 'minim\\\\S\\\\S', 'acceptable',\n",
    "                'augmented', 'augmentation', 'compensation', \n",
    "                'experimental', 'flushing', ['in', 'stream'], 'maintenance',\n",
    "                'optimum', 'restorati\\\\S{2}']\n",
    "\n",
    "    combo1_2 = ['flood', 'flow', ['water', 'level'], 'discharge']\n",
    "    \n",
    "    combo2_1 = ['compensat[a-z]{1,3}', 'conservation', 'cultural', ['cut', 'off'], \n",
    "                'design', 'fish', 'functional', 'indigenous', 'limit', 'maintenance',\n",
    "                'management', 'maximum', 'natural', 'preference', \n",
    "                'protection', 'rating', 'regime[a-z]{0,1}', 'residual',\n",
    "                'right', 'sanita(ry|tion)', 'scenario', 'standard', \n",
    "                'suitable', 'surplus', 'sustainable', 'threshold',\n",
    "                'use', 'vital']\n",
    "    combo2_2 = ['flow']\n",
    "    \n",
    "    combo3_1 = ['downstream', 'dam', 'reservoir']\n",
    "    combo3_2 = [['water', 'release'], ['flow', 'release'], 'reoperation']\n",
    "    \n",
    "    combo4_1 = ['controlled', 'artificial']\n",
    "    combo4_2 = ['flood']\n",
    "    \n",
    "    combo5_1 = ['hydrologic(al)*']\n",
    "    combo5_2 = ['requirement', 'manipulation']\n",
    "    \n",
    "    combo6_1 = ['flow', ['stream', 'flow'], 'freshwater', 'water', ['water', 'level']]\n",
    "    combo6_2 = ['abstraction', 'allocation', 'criteri\\\\S{1,2}', 'delivery*', \n",
    "                'demand', 'guideline',\n",
    "                'need', 'prescription', 'recommendation', 'recovery', 'requirement', \n",
    "                'reserve', 'restoration', 'restriction', 'withdrawal']\n",
    "    \n",
    "    search_dict = [\n",
    "            ['with', [combo1_1, combo1_2]],\n",
    "          ['with', [combo2_1, combo2_2]],\n",
    "          ['pre', [combo3_1, combo3_2]],\n",
    "          ['pre', [combo4_1, combo4_2]],\n",
    "          ['pre', [combo5_1, combo5_2]],\n",
    "          ['with', [combo6_1, combo6_2]],\n",
    "          [None, [['e-flow', 'e-flows']]]\n",
    "    ]\n",
    "    return(search_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf56b94b-eb6f-49e9-b574-b6b9dda3bcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_openalex_search_string(in_searchlist):\n",
    "    #For each combo item~~~~~~~~~~~~~~~~~~~~\n",
    "    search_list_formatted = []\n",
    "    for combo_duo in in_searchlist:\n",
    "        combo_list_formatted = []\n",
    "        for combo_list in combo_duo[1]:\n",
    "            word_group_formatted = []\n",
    "            for repattern_group in combo_list:\n",
    "                #When multiple words in a group\n",
    "                if isinstance(repattern_group, list):\n",
    "                    #print(repattern_group)\n",
    "                    #Apply find_matching_words to each\n",
    "                    repattern_group_antistemmed = []\n",
    "                    for repattern in repattern_group:\n",
    "                        k = find_matching_words(repattern)\n",
    "                        if (len(k) == 0):\n",
    "                            k = repattern\n",
    "                        if not isinstance(k, list):\n",
    "                            k = [k]\n",
    "                        repattern_group_antistemmed.append(k)\n",
    "                    #Then join them in the order with a space, no space, and with a hyphen\n",
    "                    repattern_group_antistemmed = combinate_concats(\n",
    "                        prefixes=repattern_group_antistemmed[0],\n",
    "                        suffixes=repattern_group_antistemmed[1]\n",
    "                    )\n",
    "                else:\n",
    "                    repattern_group_antistemmed = find_matching_words(repattern_group)\n",
    "                    if (len(repattern_group_antistemmed) == 0):\n",
    "                        repattern_group_antistemmed = repattern_group\n",
    "                    if not isinstance(repattern_group_antistemmed, list):\n",
    "                        repattern_group_antistemmed = [repattern_group_antistemmed]\n",
    "                        \n",
    "                #Remove duplicates\n",
    "                word_group_formatted += list(set(repattern_group_antistemmed)) #Remove duplicates\n",
    "\n",
    "            # Create a new list to store all variations\n",
    "            new_word_group = []\n",
    "            for word in word_group_formatted:\n",
    "                new_word_group.append(word)  # Add original word\n",
    "\n",
    "                # Add plural form\n",
    "                if plural_form_exists(word):\n",
    "                    plural_word = textblob_pluralize(word)\n",
    "                    new_word_group.append(plural_word)\n",
    "\n",
    "                # Add present participle\n",
    "                pre_participle = getInflection(word, 'VBG')\n",
    "                if pre_participle is not None:  # Avoid adding if it's the same\n",
    "                    if isinstance(pre_participle, list):\n",
    "                        for w in pre_particile:\n",
    "                            new_word_group.append(pre_participle)\n",
    "                    else:\n",
    "                        new_word_group.append(pre_participle[0])\n",
    "\n",
    "                # Add spelling variants (british vs americna or vice-versa)\n",
    "                spelling_variants = get_spelling_variants(word)\n",
    "                for variant in spelling_variants:\n",
    "                    if variant != word: # Avoid adding if its the same\n",
    "                      new_word_group.append(variant)\n",
    "\n",
    "            word_group_formatted = list(set(new_word_group)) # Remove dups (again, after adding variants)\n",
    "            combo_list_formatted.append(word_group_formatted)\n",
    "            \n",
    "            #Then create actual combinations for each combo duo with spaces in between when 'pre' and 'OR' when 'with'\n",
    "            #combinate_concats\n",
    "            \n",
    "            #Then combine with OR and AND, or NOT\n",
    "            #         search_list = []\n",
    "            # for combo in create_generic_search_string().values():\n",
    "            #     if len(combo) > 1:\n",
    "            #         v = combine_2w_regex(combo[1][0], combo[1][1], combo[0]=='pre')\n",
    "            #     else:\n",
    "            #         v = combo[0]\n",
    "            #     search_list.append(v)\n",
    "            # print(search_list)\n",
    "            search_list_formatted.append([combo_duo[0], combo_list_formatted])\n",
    "\n",
    "    return(search_list_formatted)\n",
    "\n",
    "    \n",
    "# def create_openalex_api_call(in_search_string):\n",
    "#     #Do NOT allow lemmatization\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ef847875-a9d5-466a-8f1e-14976eb00f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['with', [['ecohydrologic', 'eco hydrologically', 'hydro-ecological', 'hydro ecological', 'minimuss', 'optima', 'hydro ecologic', 'eco-hydrologically', 'augmentations', 'restorations', 'eco hydrologic', 'hydroecologic', 'eco hydrological', 'minimum', 'hydroecological', 'minimal', 'optimum', 'flushing', 'environmental', 'minimus', 'ecological', 'hydroecologically', 'ecologically', 'in stream', 'ecologic', 'maintenances', 'hydro ecologically', 'eco-hydrologic', 'ecohydrologically', 'maintenance', 'minima', 'in-stream', 'instream', 'compensations', 'restoratives', 'eco-hydrological', 'hydro-ecologically', 'compensation', 'experimental', 'ecohydrological', 'acceptable', 'hydro-ecologic', 'augmented', 'augmentation', 'restoration', 'restorative'], ['flow', 'waterlevel', 'discharge', 'discharges', 'flowing', 'water-level', 'discharging', 'flows', 'water level', 'flood', 'floods', 'flooding']]], ['with', [['ecohydrologic', 'eco hydrologically', 'hydro-ecological', 'hydro ecological', 'minimuss', 'optima', 'hydro ecologic', 'eco-hydrologically', 'augmentations', 'restorations', 'eco hydrologic', 'hydroecologic', 'eco hydrological', 'minimum', 'hydroecological', 'minimal', 'optimum', 'flushing', 'environmental', 'minimus', 'ecological', 'hydroecologically', 'ecologically', 'in stream', 'ecologic', 'maintenances', 'hydro ecologically', 'eco-hydrologic', 'ecohydrologically', 'maintenance', 'minima', 'in-stream', 'instream', 'compensations', 'restoratives', 'eco-hydrological', 'hydro-ecologically', 'compensation', 'experimental', 'ecohydrological', 'acceptable', 'hydro-ecologic', 'augmented', 'augmentation', 'restoration', 'restorative'], ['flow', 'waterlevel', 'discharge', 'discharges', 'flowing', 'water-level', 'discharging', 'flows', 'water level', 'flood', 'floods', 'flooding']]], ['with', [['sustainable', 'surplus', 'regimen', 'compensative', 'uses', 'residuals', 'indigenouss', 'standards', 'vitals', 'natural', 'compensatory', 'limit', 'surplussing', 'design', 'sanitations', 'standard', 'designs', 'management', 'sanitary', 'residual', 'conservation', 'compensatings', 'protection', 'right', 'surpluss', 'cut-off', 'fish', 'limiting', 'cultural', 'use', 'rights', 'using', 'cutoffs', 'functional', 'limits', 'regimes', 'suitable', 'maximum', 'maintenances', 'preferences', 'righting', 'naturals', 'compensating', 'compensate', 'ratings', 'managements', 'maintenance', 'maxima', 'protections', 'threshold', 'conservations', 'vital', 'cutoff', 'compensations', 'thresholds', 'compensation', 'scenario', 'compensates', 'preference', 'rating', 'regimens', 'scenarios', 'cut off', 'regime', 'sanitation', 'indigenous', 'compensator', 'fishing', 'designing'], ['flow', 'flows', 'flowing']]], ['with', [['sustainable', 'surplus', 'regimen', 'compensative', 'uses', 'residuals', 'indigenouss', 'standards', 'vitals', 'natural', 'compensatory', 'limit', 'surplussing', 'design', 'sanitations', 'standard', 'designs', 'management', 'sanitary', 'residual', 'conservation', 'compensatings', 'protection', 'right', 'surpluss', 'cut-off', 'fish', 'limiting', 'cultural', 'use', 'rights', 'using', 'cutoffs', 'functional', 'limits', 'regimes', 'suitable', 'maximum', 'maintenances', 'preferences', 'righting', 'naturals', 'compensating', 'compensate', 'ratings', 'managements', 'maintenance', 'maxima', 'protections', 'threshold', 'conservations', 'vital', 'cutoff', 'compensations', 'thresholds', 'compensation', 'scenario', 'compensates', 'preference', 'rating', 'regimens', 'scenarios', 'cut off', 'regime', 'sanitation', 'indigenous', 'compensator', 'fishing', 'designing'], ['flow', 'flows', 'flowing']]], ['pre', [['damming', 'dam', 'reservoir', 'dams', 'downstream', 'reservoirs'], ['flow release', 'water-release', 'flow-release', 'reoperation', 'waterrelease', 'water release', 'flowrelease']]], ['pre', [['damming', 'dam', 'reservoir', 'dams', 'downstream', 'reservoirs'], ['flow release', 'water-release', 'flow-release', 'reoperation', 'waterrelease', 'water release', 'flowrelease']]], ['pre', [['controlled', 'artificial'], ['flood', 'floods', 'flooding']]], ['pre', [['controlled', 'artificial'], ['flood', 'floods', 'flooding']]], ['pre', [['hydrologic', 'hydrological'], ['requirements', 'manipulations', 'requirement', 'manipulation']]], ['pre', [['hydrologic', 'hydrological'], ['requirements', 'manipulations', 'requirement', 'manipulation']]], ['with', [['water', 'streamflow', 'stream flow', 'flow', 'waterlevel', 'flowing', 'watering', 'water-level', 'flows', 'stream-flow', 'water level', 'freshwater', 'freshwaters'], ['withdrawal', 'requirements', 'need', 'criterias', 'guideline', 'requirement', 'deliver', 'abstractions', 'demand', 'recommendations', 'allocation', 'restorations', 'criterium', 'needs', 'restriction', 'prescriptions', 'reserving', 'recoveries', 'restrictions', 'abstraction', 'recommendation', 'delivering', 'reserve', 'demanding', 'recovery', 'allocations', 'needing', 'deliveries', 'delivers', 'delivery', 'guidelines', 'withdrawals', 'prescription', 'demands', 'criteria', 'reserves', 'restoration', 'criterion']]], ['with', [['water', 'streamflow', 'stream flow', 'flow', 'waterlevel', 'flowing', 'watering', 'water-level', 'flows', 'stream-flow', 'water level', 'freshwater', 'freshwaters'], ['withdrawal', 'requirements', 'need', 'criterias', 'guideline', 'requirement', 'deliver', 'abstractions', 'demand', 'recommendations', 'allocation', 'restorations', 'criterium', 'needs', 'restriction', 'prescriptions', 'reserving', 'recoveries', 'restrictions', 'abstraction', 'recommendation', 'delivering', 'reserve', 'demanding', 'recovery', 'allocations', 'needing', 'deliveries', 'delivers', 'delivery', 'guidelines', 'withdrawals', 'prescription', 'demands', 'criteria', 'reserves', 'restoration', 'criterion']]], [None, [['e-flow']]]]\n"
     ]
    }
   ],
   "source": [
    "in_searchlist = create_generic_search_string()\n",
    "check = create_openalex_search_string(in_searchlist)\n",
    "print(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922f369d-b7c1-4b53-9f2c-1867b6425401",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For each word in the group\n",
    "plural_list = []\n",
    "for word in word_group_formatted:\n",
    "    if plural_form_exists(word):\n",
    "        print(word)\n",
    "        plural_word = textblob_pluralize(word)\n",
    "        plural_list += plural_word\n",
    "word_group_formatted += plural_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
