{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2c60fd3a-61cb-4250-9eca-8f3f07bc16a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run lit_utility_functions_2025.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c96c664-2429-433b-8efa-e3e713eba316",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_matching_words(pattern, bound_pattern=True):\n",
    "  \"\"\"\n",
    "  Finds all English words that match a given regular expression pattern.\n",
    "\n",
    "  Args:\n",
    "    pattern: The regular expression pattern (string).\n",
    "\n",
    "  Returns:\n",
    "    A list of English words that match the pattern.  Returns an empty list if no\n",
    "    words match or if there's an invalid regex pattern.  Prints a warning if the\n",
    "    NLTK words corpus is not found.\n",
    "  \"\"\"\n",
    "  if bound_pattern:\n",
    "      pattern = f'^{pattern}$'\n",
    "    \n",
    "  try:\n",
    "    regex = re.compile(pattern)\n",
    "  except re.error as e:\n",
    "    print(f\"Invalid regular expression pattern: {e}\")\n",
    "    return []\n",
    "\n",
    "  try:\n",
    "    english_words = words.words()\n",
    "  except LookupError:\n",
    "    print(\"Warning: NLTK words corpus not found. Downloading...\")\n",
    "    try:\n",
    "      nltk.download('words')\n",
    "      english_words = words.words()\n",
    "    except Exception as e:\n",
    "      print(f\"Error downloading NLTK words corpus: {e}\")\n",
    "      return []\n",
    "        \n",
    "  matching_words = [word for word in english_words if regex.search(word)]\n",
    "  \n",
    "  return matching_words\n",
    "\n",
    "def combinate_concats(prefixes, suffixes, separators=[\" \", \"-\", \"\"]):\n",
    "    \"\"\"\n",
    "    Generates all combinations using itertools.product (most efficient).\n",
    "    \"\"\"\n",
    "    combinations = [\n",
    "        \"\".join(combination)\n",
    "        for combination in itertools.product(prefixes, separators, suffixes)\n",
    "    ]\n",
    "    return combinations\n",
    "\n",
    "def plural_form_exists(word):\n",
    "    \"\"\"\n",
    "    Checks if a plausible plural form of a word exists, with improved logic\n",
    "    and handling of irregular plurals.  Uses WordNet and a rule-based fallback.\n",
    "\n",
    "    Args:\n",
    "      word: The word (string) to check.\n",
    "\n",
    "    Returns:\n",
    "      True if a plausible plural form is found, False otherwise.\n",
    "    \"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # 1. Check if the word is already plural (common case):\n",
    "    if wordnet.synsets(word) and any(lemma.name().endswith('s') \n",
    "                                     for synset in wordnet.synsets(word)\n",
    "                                     for lemma in synset.lemmas()):\n",
    "       return True\n",
    "\n",
    "    # 2. Lemmatize the word (get the singular form):\n",
    "    lemma = lemmatizer.lemmatize(word, wordnet.NOUN)\n",
    "\n",
    "\n",
    "    #3. Check if word is the lemma (if so, it is most likely singular)\n",
    "    if lemma != word:\n",
    "        return True #Word is not the lemma (it's likely already a plural form)\n",
    "    \n",
    "    # 4. If lemma and word are the same, then add an s and try again with wordnet\n",
    "    if wordnet.synsets(word + 's'):\n",
    "        return True\n",
    "    \n",
    "    # 5. Try common plural endings\n",
    "    if word.endswith((\"s\", \"x\", \"z\", \"ch\", \"sh\")):\n",
    "        plural = word + \"es\"\n",
    "    elif word.endswith(\"y\") and len(word) > 1 and word[-2] not in \"aeiou\":\n",
    "        plural = word[:-1] + \"ies\"\n",
    "    else:\n",
    "        plural = word + \"s\"\n",
    "    \n",
    "    if wordnet.synsets(plural):\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "    \n",
    "def textblob_pluralize(word):\n",
    "    w = Word(word)\n",
    "    return w.pluralize()\n",
    "\n",
    "def get_spelling_variants(word):\n",
    "    \"\"\"Gets American and British spelling variants of a word using bream.\"\"\"\n",
    "    variants = set()\n",
    "    variants.add(word)  # Add the original word\n",
    "\n",
    "    try:\n",
    "      #The following lines will generate errors if the words are not in the\n",
    "        #dictionary. We capture these.\n",
    "        american = bream.to_american(word)\n",
    "        variants.add(american)\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        british = bream.to_british(word)\n",
    "        variants.add(british)\n",
    "    except:\n",
    "      pass\n",
    "    return list(variants)\n",
    "\n",
    "def create_generic_search_string():\n",
    "    combo1_1 = [\"ecologic\\\\S*\", [\"eco\", \"hydrologic\\\\S*\"], \n",
    "                [\"hydro\", \"ecologic\\\\S*\"],\n",
    "                'environmental', 'minim\\\\S\\\\S', 'acceptable',\n",
    "                'augmented', 'augmentation', 'compensation', \n",
    "                'experimental', 'flushing', ['in', 'stream'], 'maintenance',\n",
    "                'optimum', 'restorati\\\\S{2}']\n",
    "\n",
    "    combo1_2 = ['flood', 'flow', ['water', 'level'], 'discharge']\n",
    "    \n",
    "    combo2_1 = ['compensat[a-z]{1,3}', 'conservation', 'cultural', ['cut', 'off'], \n",
    "                'design', 'fish', 'functional', 'indigenous', 'limit', 'maintenance',\n",
    "                'management', 'maximum', 'natural', 'preference', \n",
    "                'protection', 'rating', 'regime[a-z]{0,1}', 'residual',\n",
    "                'right', 'sanita(ry|tion)', 'scenario', 'standard', \n",
    "                'suitable', 'surplus', 'sustainable', 'threshold',\n",
    "                'use', 'vital']\n",
    "    combo2_2 = ['flow']\n",
    "    \n",
    "    combo3_1 = ['downstream', 'dam', 'reservoir']\n",
    "    combo3_2 = [['water', 'release'], ['flow', 'release'], 'reoperation']\n",
    "    \n",
    "    combo4_1 = ['controlled', 'artificial']\n",
    "    combo4_2 = ['flood']\n",
    "    \n",
    "    combo5_1 = ['hydrologic(al)*']\n",
    "    combo5_2 = ['requirement', 'manipulation']\n",
    "    \n",
    "    combo6_1 = ['flow', ['stream', 'flow'], 'freshwater', 'water', ['water', 'level']]\n",
    "    combo6_2 = ['abstraction', 'allocation', 'criteri\\\\S{1,2}', 'delivery*', \n",
    "                'demand', 'guideline',\n",
    "                'need', 'prescription', 'recommendation', 'recovery', 'requirement', \n",
    "                'reserve', 'restoration', 'restriction', 'withdrawal']\n",
    "    \n",
    "    search_dict = [\n",
    "            ['with', [combo1_1, combo1_2]],\n",
    "          ['with', [combo2_1, combo2_2]],\n",
    "          ['pre', [combo3_1, combo3_2]],\n",
    "          ['pre', [combo4_1, combo4_2]],\n",
    "          ['pre', [combo5_1, combo5_2]],\n",
    "          ['with', [combo6_1, combo6_2]],\n",
    "          [None, [['e-flow', 'e-flows']]]\n",
    "    ]\n",
    "    return(search_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bf56b94b-eb6f-49e9-b574-b6b9dda3bcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_openalex_search_string(in_searchlist):\n",
    "    search_list_formatted = []\n",
    "    #For each combo item~~~~~~~~~~~~~~~~~~~~\n",
    "    for combo_duo in in_searchlist:\n",
    "        combo_list_formatted = []\n",
    "        for combo_list in combo_duo[1]:\n",
    "            word_group_formatted = []\n",
    "            for repattern_group in combo_list:\n",
    "                #When multiple words in a group\n",
    "                if isinstance(repattern_group, list):\n",
    "                    #print(repattern_group)\n",
    "                    #Apply find_matching_words to each\n",
    "                    repattern_group_antistemmed = []\n",
    "                    for repattern in repattern_group:\n",
    "                        k = find_matching_words(repattern)\n",
    "                        if (len(k) == 0):\n",
    "                            k = repattern\n",
    "                        if not isinstance(k, list):\n",
    "                            k = [k]\n",
    "                        repattern_group_antistemmed.append(k)\n",
    "                    #Then join them in the order with space, no space, and hyphen\n",
    "                    repattern_group_antistemmed = combinate_concats(\n",
    "                        prefixes=repattern_group_antistemmed[0],\n",
    "                        suffixes=repattern_group_antistemmed[1]\n",
    "                    )\n",
    "                else:\n",
    "                    repattern_group_antistemmed = find_matching_words(repattern_group)\n",
    "                    if (len(repattern_group_antistemmed) == 0):\n",
    "                        repattern_group_antistemmed = repattern_group\n",
    "                    if not isinstance(repattern_group_antistemmed, list):\n",
    "                        repattern_group_antistemmed = [repattern_group_antistemmed]\n",
    "                \n",
    "                #Remove duplicates\n",
    "                word_group_formatted += list(set(repattern_group_antistemmed))\n",
    "                \n",
    "            # Create a new list to store all variations\n",
    "            new_word_group = []\n",
    "            for word in word_group_formatted:\n",
    "                new_word_group.append(word)  # Add original word\n",
    "\n",
    "                # Add plural form\n",
    "                if plural_form_exists(word):\n",
    "                    plural_word = textblob_pluralize(word)\n",
    "                    new_word_group.append(plural_word)\n",
    "\n",
    "                # Add present participle\n",
    "                pre_participle = getInflection(word, 'VBG')\n",
    "                if pre_participle is not None:  # Avoid adding if it's the same\n",
    "                    if isinstance(pre_participle, list):\n",
    "                        for w in pre_particile:\n",
    "                            new_word_group.append(pre_participle)\n",
    "                    else:\n",
    "                        new_word_group.append(pre_participle[0])\n",
    "\n",
    "                # Add spelling variants (british vs americna or vice-versa)\n",
    "                spelling_variants = get_spelling_variants(word)\n",
    "                for variant in spelling_variants:\n",
    "                    if variant != word: # Avoid adding if its the same\n",
    "                      new_word_group.append(variant)\n",
    "\n",
    "            # Remove duplicates (again, after adding variants)\n",
    "            word_group_formatted = list(set(new_word_group))\n",
    "\n",
    "            #Combine word within word_group/combo_list\n",
    "            combo_list_formatted.append(word_group_formatted)\n",
    "            \n",
    "        #Then create actual combinations for each combo duo\n",
    "        if combo_duo[0] == 'pre':\n",
    "            #Cretae combinations of all terms separated by a space\n",
    "            combo_duo_formatted = combinate_concats(\n",
    "                combo_list_formatted[0], \n",
    "                combo_list_formatted[1],\n",
    "                separators=\" \"\n",
    "            )\n",
    "        elif combo_duo[0] == 'with':\n",
    "            #Create two blocks, OR within each block, AND between the two\n",
    "            combo_duo_formatted = [\n",
    "                f'{recomb(combo_list_formatted[0], recomb_sep = ' OR ')} \\\n",
    "                AND {recomb(combo_list_formatted[1], recomb_sep = ' OR ')}'\n",
    "            ]\n",
    "\n",
    "        elif combo_duo[0] is None:\n",
    "            combo_duo_formatted = combo_list_formatted[0]\n",
    "        \n",
    "        search_list_formatted.extend(combo_duo_formatted)\n",
    "    \n",
    "    #Add ORs between all terms\n",
    "    search_list_formatted = recomb(search_list_formatted, recomb_sep = ' OR ')\n",
    "\n",
    "    return(search_list_formatted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ef847875-a9d5-466a-8f1e-14976eb00f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((((hydro-ecologically) OR (hydro ecologic) OR (eco hydrological) OR (augmented) OR (hydroecologic) OR (minimus) OR (ecohydrological) OR (in stream) OR (eco hydrologic) OR (ecologically) OR (augmentations) OR (instream) OR (flushing) OR (augmentation) OR (eco hydrologically) OR (hydroecological) OR (eco-hydrological) OR (hydroecologically) OR (ecologic) OR (acceptable) OR (ecohydrologically) OR (hydro ecological) OR (restoration) OR (maintenances) OR (hydro-ecological) OR (minimuss) OR (optimum) OR (eco-hydrologically) OR (hydro ecologically) OR (optima) OR (maintenance) OR (restorative) OR (compensations) OR (in-stream) OR (ecological) OR (restorations) OR (eco-hydrologic) OR (minimal) OR (ecohydrologic) OR (minima) OR (minimum) OR (hydro-ecologic) OR (compensation) OR (restoratives) OR (environmental) OR (experimental))                 AND ((flooding) OR(flow) OR(flood) OR(discharges) OR(flowing) OR(waterlevel) OR(discharging) OR(flows) OR(discharge) OR(water level) OR(water-level) OR(floods))) OR(((compensating) OR (compensator) OR (sanitations) OR (uses) OR (maxima) OR (limiting) OR (right) OR (limit) OR (vital) OR (preferences) OR (protection) OR (naturals) OR (management) OR (compensatings) OR (conservations) OR (regimens) OR (thresholds) OR (rights) OR (rating) OR (indigenous) OR (sanitary) OR (standards) OR (designs) OR (regimen) OR (scenario) OR (managements) OR (vitals) OR (fishing) OR (preference) OR (residuals) OR (design) OR (residual) OR (surplus) OR (sanitation) OR (standard) OR (use) OR (maintenances) OR (fish) OR (cut-off) OR (using) OR (sustainable) OR (cultural) OR (cutoff) OR (compensate) OR (functional) OR (surpluss) OR (limits) OR (compensatory) OR (maintenance) OR (protections) OR (compensations) OR (threshold) OR (surplussing) OR (maximum) OR (regimes) OR (cut off) OR (natural) OR (regime) OR (compensates) OR (compensation) OR (ratings) OR (compensative) OR (indigenouss) OR (scenarios) OR (righting) OR (suitable) OR (conservation) OR (cutoffs) OR (designing))                 AND ((flowing) OR(flows) OR(flow))) OR(downstream water-release) OR(downstream reoperation) OR(downstream flow release) OR(downstream flow-release) OR(downstream water release) OR(downstream waterrelease) OR(downstream flowrelease) OR(damming water-release) OR(damming reoperation) OR(damming flow release) OR(damming flow-release) OR(damming water release) OR(damming waterrelease) OR(damming flowrelease) OR(reservoir water-release) OR(reservoir reoperation) OR(reservoir flow release) OR(reservoir flow-release) OR(reservoir water release) OR(reservoir waterrelease) OR(reservoir flowrelease) OR(dams water-release) OR(dams reoperation) OR(dams flow release) OR(dams flow-release) OR(dams water release) OR(dams waterrelease) OR(dams flowrelease) OR(reservoirs water-release) OR(reservoirs reoperation) OR(reservoirs flow release) OR(reservoirs flow-release) OR(reservoirs water release) OR(reservoirs waterrelease) OR(reservoirs flowrelease) OR(dam water-release) OR(dam reoperation) OR(dam flow release) OR(dam flow-release) OR(dam water release) OR(dam waterrelease) OR(dam flowrelease) OR(artificial flooding) OR(artificial floods) OR(artificial flood) OR(controlled flooding) OR(controlled floods) OR(controlled flood) OR(hydrologic manipulations) OR(hydrologic requirement) OR(hydrologic requirements) OR(hydrologic manipulation) OR(hydrological manipulations) OR(hydrological requirement) OR(hydrological requirements) OR(hydrological manipulation) OR(((flow) OR (streamflow) OR (watering) OR (water) OR (flowing) OR (stream flow) OR (freshwater) OR (freshwaters) OR (waterlevel) OR (flows) OR (water level) OR (water-level) OR (stream-flow))                 AND ((criterium) OR(demands) OR(guidelines) OR(reserve) OR(allocations) OR(delivery) OR(reserving) OR(prescriptions) OR(requirement) OR(demand) OR(abstraction) OR(needs) OR(requirements) OR(prescription) OR(restoration) OR(need) OR(criteria) OR(recovery) OR(guideline) OR(withdrawals) OR(demanding) OR(delivers) OR(delivering) OR(allocation) OR(recoveries) OR(reserves) OR(recommendations) OR(abstractions) OR(restorations) OR(criterias) OR(criterion) OR(deliveries) OR(deliver) OR(needing) OR(recommendation) OR(restrictions) OR(withdrawal) OR(restriction))) OR(e-flow) OR(e-flows))\n"
     ]
    }
   ],
   "source": [
    "in_searchlist = create_generic_search_string()\n",
    "check = create_openalex_search_string(in_searchlist)\n",
    "print(check)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
