{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99592c59-ac28-4801-b22c-16df6f0de8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run create_search_strings.ipynb\n",
    "%run set_up.py\n",
    "\n",
    "import pyalex #https://github.com/J535D165/pyalex\n",
    "from pyalex import config\n",
    "from pyalex import Works\n",
    "\n",
    "config.max_retries = 1\n",
    "pyalex.config.email = \"mathis.messager@mail.mcgill.ca\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7737d4df-02b7-4ced-b397-efd5019d0ce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((((flushing) OR (hydro-ecological) OR (hydro-ecologic) OR (minimus) OR (ecohydrologically) OR (acceptable) OR (eco hydrologically) OR (hydroecologically) OR (restoration) OR (hydroecological) OR (compensations) OR (experimental) OR (instream) OR (maintenances) OR (in-stream) OR (restorative) OR (eco-hydrologically) OR (ecological) OR (augmentations) OR (eco hydrologic) OR (in stream) OR (hydro ecologic) OR (hydro ecological) OR (ecohydrological) OR (minimum) OR (minima) OR (eco-hydrological) OR (ecologically) OR (augmented) OR (augmentation) OR (restoratives) OR (hydro-ecologically) OR (hydroecologic) OR (optimum) OR (eco hydrological) OR (eco-hydrologic) OR (minimal) OR (compensation) OR (ecologic) OR (minimuss) OR (hydro ecologically) OR (maintenance) OR (environmental) OR (ecohydrologic) OR (restorations) OR (optima))                 AND ((flood) OR (discharges) OR (flows) OR (waterlevel) OR (water-level) OR (discharging) OR (floods) OR (flooding) OR (discharge) OR (water level) OR (flow) OR (flowing))) OR (((regimens) OR (compensates) OR (compensative) OR (sanitation) OR (thresholds) OR (standard) OR (residuals) OR (maxima) OR (management) OR (residual) OR (compensate) OR (limits) OR (compensations) OR (right) OR (sanitations) OR (maintenances) OR (designs) OR (protection) OR (righting) OR (limiting) OR (scenarios) OR (preferences) OR (surplus) OR (uses) OR (vital) OR (using) OR (cutoffs) OR (cut-off) OR (maximum) OR (compensatings) OR (compensating) OR (cutoff) OR (ratings) OR (rights) OR (indigenous) OR (sustainable) OR (use) OR (conservation) OR (designing) OR (functional) OR (regimen) OR (design) OR (vitals) OR (standards) OR (protections) OR (cultural) OR (fish) OR (compensator) OR (compensatory) OR (regimes) OR (conservations) OR (indigenouss) OR (surpluss) OR (compensation) OR (scenario) OR (suitable) OR (fishing) OR (naturals) OR (threshold) OR (natural) OR (regime) OR (rating) OR (limit) OR (maintenance) OR (sanitary) OR (managements) OR (preference) OR (cut off) OR (surplussing))                 AND ((flows) OR (flow) OR (flowing))) OR (\"dam water release\") OR (\"dam water-release\") OR (\"dam flowrelease\") OR (\"dam flow-release\") OR (\"dam reoperation\") OR (\"dam flow release\") OR (\"dam waterrelease\") OR (\"reservoirs water release\") OR (\"reservoirs water-release\") OR (\"reservoirs flowrelease\") OR (\"reservoirs flow-release\") OR (\"reservoirs reoperation\") OR (\"reservoirs flow release\") OR (\"reservoirs waterrelease\") OR (\"downstream water release\") OR (\"downstream water-release\") OR (\"downstream flowrelease\") OR (\"downstream flow-release\") OR (\"downstream reoperation\") OR (\"downstream flow release\") OR (\"downstream waterrelease\") OR (\"reservoir water release\") OR (\"reservoir water-release\") OR (\"reservoir flowrelease\") OR (\"reservoir flow-release\") OR (\"reservoir reoperation\") OR (\"reservoir flow release\") OR (\"reservoir waterrelease\") OR (\"dams water release\") OR (\"dams water-release\") OR (\"dams flowrelease\") OR (\"dams flow-release\") OR (\"dams reoperation\") OR (\"dams flow release\") OR (\"dams waterrelease\") OR (\"damming water release\") OR (\"damming water-release\") OR (\"damming flowrelease\") OR (\"damming flow-release\") OR (\"damming reoperation\") OR (\"damming flow release\") OR (\"damming waterrelease\") OR (\"controlled floods\") OR (\"controlled flooding\") OR (\"controlled flood\") OR (\"artificial floods\") OR (\"artificial flooding\") OR (\"artificial flood\") OR (\"hydrological manipulation\") OR (\"hydrological requirement\") OR (\"hydrological manipulations\") OR (\"hydrological requirements\") OR (\"hydrologic manipulation\") OR (\"hydrologic requirement\") OR (\"hydrologic manipulations\") OR (\"hydrologic requirements\") OR (((water) OR (flows) OR (streamflow) OR (waterlevel) OR (water-level) OR (stream flow) OR (freshwaters) OR (watering) OR (freshwater) OR (water level) OR (flow) OR (stream-flow) OR (flowing))                 AND ((criterium) OR (criterion) OR (needs) OR (delivers) OR (requirement) OR (restoration) OR (withdrawals) OR (prescriptions) OR (criterias) OR (deliveries) OR (demand) OR (reserve) OR (requirements) OR (demands) OR (allocations) OR (allocation) OR (reserving) OR (reserves) OR (withdrawal) OR (demanding) OR (delivery) OR (needing) OR (recoveries) OR (recommendation) OR (prescription) OR (recommendations) OR (guidelines) OR (guideline) OR (restriction) OR (abstractions) OR (abstraction) OR (recovery) OR (deliver) OR (criteria) OR (restrictions) OR (delivering) OR (need) OR (restorations))) OR (e-flows) OR (e-flow))\n"
     ]
    }
   ],
   "source": [
    "search_terms = create_generic_search_terms()\n",
    "oalex_string = create_openalex_search_string(search_terms)\n",
    "print(oalex_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3f4d181d-ea17-4278-b4b5-26c4331e4fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_last_url_segment(url):\n",
    "    \"\"\"\n",
    "    Extracts the last segment of a URL path.  Handles various URL formats\n",
    "    and potential errors robustly.\n",
    "\n",
    "    Args:\n",
    "        url: The URL string.\n",
    "\n",
    "    Returns:\n",
    "        The last segment of the URL path, or None if the URL is invalid\n",
    "        or has no path.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        parsed_url = urlparse(url)\n",
    "        path = parsed_url.path\n",
    "        if not path:\n",
    "            return None  # No path component\n",
    "\n",
    "        # Split the path by '/' and get the last element\n",
    "        segments = path.split('/')\n",
    "        return segments[-1]  # Handle cases with trailing slashes correctly\n",
    "\n",
    "    except Exception:  # Catch any parsing errors\n",
    "        return None\n",
    "\n",
    "def extract_concept_from_url_df(df, url_col, include_col=None):\n",
    "    \"\"\"\n",
    "    Extracts the last segment of URLs from a specific column in a DataFrame,\n",
    "    filtering by a boolean column, and adds the result as a new column.\n",
    "\n",
    "    Args:\n",
    "      df: The Pandas DataFrame.\n",
    "      url_col: The name of the column containing URLs (string).\n",
    "      include_col: The name of the boolean column to filter by (string).\n",
    "\n",
    "    Returns:\n",
    "        A new Pandas DataFrame with an additional column 'openalex_id_last_segment'\n",
    "        containing the extracted last segment, or None if the input is invalid.\n",
    "    \"\"\"\n",
    "    # Input validation: Check for required columns\n",
    "    required_columns = [url_col]\n",
    "    if include_col is not None:\n",
    "        required_columns.append(include_col)\n",
    "    if not all(col in df.columns for col in required_columns):\n",
    "        print(\"DataFrame is missing some columns.\")\n",
    "        return None\n",
    "\n",
    "    # Make a copy to avoid modifying the original DataFrame\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    if include_col is not None:\n",
    "        # Convert 'Include?' (or whatever include_col is) to boolean, handling various representations.\n",
    "        df_copy[include_col] = df_copy[include_col].astype(str).str.lower().isin(['y', 'yes', 'true', '1', 't'])\n",
    "        # Apply the extraction function ONLY to rows where 'include_col' is True,\n",
    "        # and ONLY to the 'url_col' of those rows. Use .loc for proper indexing.\n",
    "        included_clist = df_copy.loc[df_copy[include_col], url_col].apply(extract_last_url_segment)\n",
    "    else:\n",
    "        included_clist = df_copy.loc[:, url_col].apply(extract_last_url_segment)\n",
    "\n",
    "    return included_clist.tolist()\n",
    "\n",
    "#Get open alex concepts to filter with\n",
    "concepts_toinclude_pd = pd.read_csv(\n",
    "    os.path.join(datdir, 'openalex_concepts_toinclude.csv'))\n",
    "concepts_toinclude_list =  extract_concept_from_url_df(\n",
    "    df = concepts_toinclude_pd,\n",
    "    url_col = 'openalex_id', \n",
    "    include_col = 'include')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "435b5d24-3723-46bc-8eb2-e3886726baaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.openalex.org/works?search=environmental+flows&filter=concept.id:c26271046%7Cc47768531&cursor=%2A&per-page=200\n"
     ]
    }
   ],
   "source": [
    "\n",
    "query = Works().search(\"environmental flows\").filter(concept={\"id\": \"c26271046|c47768531\"})\n",
    "\n",
    "record_list=[record for record in itertools.chain(*query.paginate(per_page=200, n_max=10))]\n",
    "\n",
    "\n",
    "# Works().search_filter(title=\"cubist\").get()\n",
    "# Works().filter(publication_year=2020, is_oa=True).select([\"id\", \"doi\"]).get()\n",
    "\n",
    "# #Serialize\n",
    "# #All results from PyAlex can be serialized. For example, save the results to a JSON file:\n",
    "# import json\n",
    "# from pathlib import Path\n",
    "# from pyalex import Work\n",
    "\n",
    "# with open(Path(\"works.json\"), \"w\") as f:\n",
    "#     json.dump(Works().get(), f)\n",
    "\n",
    "# # with open(Path(\"works.json\")) as f:\n",
    "# #     works = [Work(w) for w in json.load(f)]\n",
    "print(query.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "425d50ba-7def-46e2-90c7-28c9d4c8dd77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global Patterns of Material Flows and their Socio-Economic and Environmental Implications: A MFA Study on All Countries World-Wide from 1980 to 2009\n"
     ]
    }
   ],
   "source": [
    "print(record_list[2]['display_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4e1159-6904-464f-9956-276c3523b1ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "~~~~~ Search for works in OpenAlex based on search string ~~~~~~~~~~~~~~~~~~~~~~\n",
    "Reference info on the API: \n",
    "# https://docs.openalex.org/how-to-use-the-api/get-lists-of-entities/search-entities\n",
    "# https://docs.openalex.org/api-entities/works/search-works\n",
    "\n",
    "#EX: https://api.openalex.org/works?search=(elmo AND \"sesame street\") NOT (cookie OR monster)\n",
    "#Filter categories based on csv\n",
    "#do not lemmatize\n",
    "#&per-page=100&cursor=*\n",
    "\n",
    "#~~~~~~~~~~~~~~~~ PAGING ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "Basic paging only works to get the first 10,000 results of any list. If you want to see more than 10,000 results, you'll need to use cursor paging.\n",
    "To use cursor paging, you request a cursor by adding the cursor=* parameter-value pair to your query.\n",
    "    Get a cursor in order to start cursor pagination:\n",
    "    https://api.openalex.org/works?filter=publication_year:2020&per-page=100&cursor=*\n",
    "The response to your query will include a next_cursor value in the response's meta object. Here's what it looks like:\n",
    "{\n",
    "  \"meta\": {\n",
    "    \"count\": 8695857,\n",
    "    \"db_response_time_ms\": 28,\n",
    "    \"page\": null,\n",
    "    \"per_page\": 100,\n",
    "    \"next_cursor\": \"IlsxNjA5MzcyODAwMDAwLCAnaHR0cHM6Ly9vcGVuYWxleC5vcmcvVzI0ODg0OTk3NjQnXSI=\"\n",
    "  },\n",
    "  \"results\" : [\n",
    "    // the first page of results\n",
    "  ]\n",
    "}\n",
    "\n",
    "To retrieve the next page of results, copy the meta.next_cursor value into the cursor field of your next request.\n",
    "\n",
    "    Get the next page of results using a cursor value:\n",
    "    https://api.openalex.org/works?filter=publication_year:2020&per-page=100&cursor=IlsxNjA5MzcyODAwMDAwLCAnaHR0cHM6Ly9vcGVuYWxleC5vcmcvVzI0ODg0OTk3NjQnXSI=\n",
    "\n",
    "To get all the results, keep repeating this process until meta.next_cursor is null and the results set is empty.\n",
    "'''\n",
    "\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "def searching(query_string, broad='no', has_ngrams='true', \n",
    "              does_date_matter='no', from_date='1976-01-01'):\n",
    "    if broad == 'no':\n",
    "        if does_date_matter == 'yes':\n",
    "            institution = requests.get(\n",
    "                f'https://api.openalex.org/works?filter=abstract.search:{query_string},\\\n",
    "                has_ngrams:{has_ngrams},from_publication_date:{from_date},to_publication_date:{to_date}&page=1&per-page=20'\n",
    "            ).json()\n",
    "        else:\n",
    "            institution = requests.get(\n",
    "                f'https://api.openalex.org/works?filter=title.search:{query_string},\\\n",
    "                has_ngrams:{has_ngrams},&page=1&per-page=20'\n",
    "            ).json()\n",
    "    elif broad == 'yes':\n",
    "        institution = requests.get(\n",
    "            f'https://api.openalex.org/works?search={query_string}&page=1&per-page=20'\n",
    "        ).json()\n",
    "    return institution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
